{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Long Short-Term Memory Layer**\n",
    "This [jupyter notebook](https://jupyter.org/) includes the [long short-term memory layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM) (LSTM; a specialised recurrent neural network for time series; see [here](https://deeplearning.cs.cmu.edu/F23/document/readings/LSTM.pdf)) model that utilizes expenses of environmental safety and public health as input and displays the expected [environmental burden of disease](https://www.who.int/data/gho/indicator-metadata-registry/imr-details/2393) as output.\n",
    "\n",
    "**Packages used**\n",
    "* [tensorflow](https://www.tensorflow.org/) is a machine learning platform including LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country should be one-hot-encoded\n",
    "Year | Country A | Country B | Country C | Country D | Country E | Health Expenditure | Environmental Expenditure | Feature 1 | Feature 2 | Feature 3 | Feature 4 | Feature 5\n",
    "-----|-----------|-----------|-----------|-----------|-----------|--------------------|---------------------------|-----------|-----------|-----------|-----------|-----------\n",
    "2014 | 1         | 0         | 0         | 0         | 0         | 10000              | 5000                      | 200       | 300       | 150       | 250       | 180\n",
    "2015 | 1         | 0         | 0         | 0         | 0         | 11000              | 5200                      | 220       | 320       | 170       | 270       | 190\n",
    "...  | ...       | ...       | ...       | ...       | ...       | ...                | ...                       | ...       | ...       | ...       | ...       | ...\n",
    "2023 | 0         | 0         | 0         | 0         | 1         | 15000              | 7000                      | 300       | 400       | 250       | 350       | 270\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "def build_model(input_shape, output_shape):\n",
    "    # Define input layer\n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    # LSTM layer\n",
    "    lstm = LSTM(128, return_sequences=True)(inputs)\n",
    "    # Attention layer\n",
    "    attention = Attention()([lstm, lstm])\n",
    "    # Dense layer for output\n",
    "    outputs = Dense(output_shape, activation='linear')(attention)  # Use linear activation for regression\n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Apply scaling todata\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "#scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on training data and transform both training and test data\n",
    "#X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_val_scaled = scaler.transform(X_val)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define input and output dimensions\n",
    "time_steps = 10  # Number of years\n",
    "input_features = 12  # Number of features per year (including country and expenditures)\n",
    "output_features = 5  # Assuming you have 5 output features (environmental burdens)\n",
    "\n",
    "# Compile model\n",
    "model = build_model(input_shape=(time_steps, input_features), output_shape=output_features)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])  # Use MSE for regression, mae for evaluation\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Mean Absolute Error: {mae}')\n",
    "\n",
    "# Make prediction\n",
    "predictions = model.predict(X_new_data)\n",
    "\n",
    "# Assuming user_input contains the estimated expenditures and the country name\n",
    "#user_input_scaled = scaler.transform(user_input)\n",
    "#predictions = model.predict(user_input_scaled)\n",
    "\n",
    "# Save and load model\n",
    "model.save('LSTM_with_attention.h5')\n",
    "loaded_model = tf.keras.models.load_model('LSTM_with_attention.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "def build_model(input_shape, output_shape):\n",
    "    # Define input layer\n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    # LSTM layer\n",
    "    lstm = LSTM(128, return_sequences=True)(inputs)\n",
    "    # Attention layer\n",
    "    attention = Attention()([lstm, lstm])\n",
    "    # Dense layer for output\n",
    "    outputs = Dense(output_shape, activation='softmax')(attention)\n",
    "    # Define the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Compile model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[43mtime_steps\u001b[49m, input_features), output_shape\u001b[38;5;241m=\u001b[39moutput_features)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time_steps' is not defined"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model = build_model(input_shape=(time_steps, input_features), output_shape=output_features)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "predictions = model.predict(X_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load model\n",
    "model.save('LSTM_with_attention.h5')\n",
    "loaded_model = tf.keras.models.load_model('LSTM_with_attention.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
